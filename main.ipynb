{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c70e91e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7065cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.preprocessing import AudioPreprocessor\n",
    "from modules.feature_extraction import FeatureExtractor\n",
    "from modules.pipelines import ModelPipeline\n",
    "from modules.evaluate import PerformanceAnalyzer\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b2f43",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import run_config, NUM_WORKERS, DATA_DIR, AUDIO_PATH\n",
    "\n",
    "run_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392b58d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ec207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                           path                          sentence  up_votes  \\\n",
       "0  common_voice_en_19687170.mp3  He associated with the Formists.         2   \n",
       "\n",
       "   down_votes      age  gender accent  label  \n",
       "0           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"filtered_data_labeled.tsv\", sep='\\t')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7518fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>data\\audios\\common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                                       path                          sentence  \\\n",
       "0  data\\audios\\common_voice_en_19687170.mp3  He associated with the Formists.   \n",
       "\n",
       "   up_votes  down_votes      age  gender accent  label  \n",
       "0         2           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path'] = df['path'].apply(lambda x: AUDIO_PATH / x)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a52cb",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "\n",
    "# === Parallel Processing ===\n",
    "def process_sample(\n",
    "    row: pd.Series, \n",
    "    idx: int, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool\n",
    ") -> Optional[Tuple[int, np.ndarray, str]]:\n",
    "\n",
    "    y_proc: Optional[np.ndarray] = preprocessor.load_cached_preprocessed(idx) if not force_update else None\n",
    "    \n",
    "    # Load and preprocess audio if not cached or force_update is True\n",
    "    if y_proc is None or force_update:\n",
    "        y_raw: Optional[np.ndarray] = preprocessor.load_audio(row['path'])\n",
    "        if y_raw is None:\n",
    "            # print(f\"Failed to load audio for index {idx}.\")\n",
    "            return None\n",
    "        y_proc = preprocessor.preprocess(y_raw)\n",
    "        preprocessor.cache_preprocessed(idx, y_proc, force_update)\n",
    "    \n",
    "    # Extract features\n",
    "    feat = extractor.extract(y_proc, sr=16000, mode=mode)\n",
    "    return idx, feat, row['label']\n",
    "\n",
    "\n",
    "def process_batch(\n",
    "    batch_df: pd.DataFrame, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool, \n",
    "    offset: int = 0\n",
    ") -> List[Tuple[int, np.ndarray, str]]:\n",
    "    results: List[Tuple[int, np.ndarray, str]] = []\n",
    "    \n",
    "    for i, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Batch {offset}\", leave=False):\n",
    "        result: Optional[Tuple[int, np.ndarray, str]] = process_sample(row, i, mode, preprocessor, extractor, force_update)\n",
    "        if result: results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25f1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_parallel(df, mode=\"traditional\", force_update_preprocessing=False, force_update_features=False, batch_size=None):\n",
    "    print(f\"ðŸ”„ Preparing features in {mode} mode...\")\n",
    "    extractor = FeatureExtractor()\n",
    "    X_cached, y_cached = extractor.load_cached_features(mode)\n",
    "    if X_cached is not None and not force_update_features:\n",
    "        return X_cached, y_cached\n",
    "    \n",
    "    print(\"ðŸ”„ Loading and preprocessing audio...\")\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    features_dict, labels_dict = {}, {}\n",
    "\n",
    "    # Auto-select batch size based on available memor\n",
    "    total_memory_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "    est_mem_per_sample = 0.01 if mode == \"traditional\" else 0.2\n",
    "    est_batch_size = max(10, int((total_memory_gb * 0.4) / est_mem_per_sample))\n",
    "    batch_size = batch_size or min(est_batch_size, len(df) // NUM_WORKERS)\n",
    "    if total_memory_gb < 2:\n",
    "        print(\"âš ï¸ Warning: Low memory detected. Reducing batch size to avoid OOM errors.\")\n",
    "        batch_size = min(batch_size, 10)\n",
    "    print(f\"ðŸ§  Auto-selected batch size: {batch_size} (Estimated memory per sample: {est_mem_per_sample:.2f} GB, Total RAM: {total_memory_gb:.2f} GB)\")\n",
    "\n",
    "    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    print(f\"ðŸ”„ Total batches: {len(batches)}\")\n",
    "\n",
    "    print(\"ðŸ“¦ Processing batches:\")\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_batch, batch, mode, preprocessor, extractor, force_update_preprocessing, i): i\n",
    "            for i, batch in enumerate(batches)\n",
    "            }\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"ðŸ“Š Batches Done\"):\n",
    "            batch_results = future.result()\n",
    "            if batch_results:\n",
    "                for idx, feat, label in batch_results:\n",
    "                    features_dict[idx] = feat\n",
    "                    labels_dict[idx] = label\n",
    "\n",
    "    print(\"ðŸ”„ Finished processing batches.\")\n",
    "    # for i in range(len(batches)): extractor.remove_cached_features(mode, index=i)\n",
    "\n",
    "    sorted_indices = sorted(features_dict.keys())\n",
    "    X = np.array([features_dict[i] for i in sorted_indices])\n",
    "    y = np.array([labels_dict[i] for i in sorted_indices])\n",
    "    extractor.cache_features(X, y, mode=mode, force_update=force_update_features)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cd877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preparing features in traditional mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_features_parallel(df, mode=\"traditional\", force_update_features=False, force_update_preprocessing=False) # , batch_size=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dfa4d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172158, 147), (172158,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb979e43",
   "metadata": {},
   "source": [
    "# Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Batch Inference Utility ===\n",
    "def run_batch_inference(model, input_folder, output_path, sr=16000, feature_mode=\"traditional\"):\n",
    "    extractor = FeatureExtractor()\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    results = []\n",
    "\n",
    "    for file in Path(input_folder).rglob(\"*.wav\"):\n",
    "        y = preprocessor.preprocess(preprocessor.load_audio(str(file), sr=sr))\n",
    "        if y is not None:\n",
    "            x = extractor.extract(y, sr=sr, mode=feature_mode).reshape(1, -1)\n",
    "            pred = model.predict(x)[0]\n",
    "            results.append({\"file\": file.name, \"prediction\": pred})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Batch inference saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
