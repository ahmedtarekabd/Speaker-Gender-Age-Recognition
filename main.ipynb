{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c70e91e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7065cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.preprocessing import AudioPreprocessor\n",
    "from modules.feature_extraction import FeatureExtractor\n",
    "from modules.pipelines import ModelPipeline\n",
    "# from modules.evaluate import PerformanceAnalyzer\n",
    "\n",
    "from models.catboost import CatBoostModel\n",
    "from models.lightgbm import LightGBMModel\n",
    "from models.xgboost import XGBoostModel\n",
    "# from models.gmboost import GradientBoostingModel\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b2f43",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import run_config, NUM_WORKERS, DATA_DIR, AUDIO_PATH\n",
    "\n",
    "run_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392b58d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ec207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                           path                          sentence  up_votes  \\\n",
       "0  common_voice_en_19687170.mp3  He associated with the Formists.         2   \n",
       "\n",
       "   down_votes      age  gender accent  label  \n",
       "0           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"filtered_data_labeled.tsv\", sep='\\t')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7518fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>data\\audios\\common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                                       path                          sentence  \\\n",
       "0  data\\audios\\common_voice_en_19687170.mp3  He associated with the Formists.   \n",
       "\n",
       "   up_votes  down_votes      age  gender accent  label  \n",
       "0         2           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path'] = df['path'].apply(lambda x: AUDIO_PATH / x)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a52cb",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "\n",
    "# === Parallel Processing ===\n",
    "def process_sample(\n",
    "    row: pd.Series, \n",
    "    idx: int, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool\n",
    ") -> Optional[Tuple[int, np.ndarray, str]]:\n",
    "\n",
    "    y_proc: Optional[np.ndarray] = preprocessor.load_cached_preprocessed(idx) if not force_update else None\n",
    "    \n",
    "    # Load and preprocess audio if not cached or force_update is True\n",
    "    if y_proc is None or force_update:\n",
    "        y_raw: Optional[np.ndarray] = preprocessor.load_audio(row['path'])\n",
    "        if y_raw is None:\n",
    "            # print(f\"Failed to load audio for index {idx}.\")\n",
    "            return None\n",
    "        y_proc = preprocessor.preprocess(y_raw)\n",
    "        preprocessor.cache_preprocessed(idx, y_proc, force_update)\n",
    "    \n",
    "    # Extract features\n",
    "    feat = extractor.extract(y_proc, sr=16000, mode=mode)\n",
    "    return idx, feat, row['label']\n",
    "\n",
    "\n",
    "def process_batch(\n",
    "    batch_df: pd.DataFrame, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool, \n",
    "    offset: int = 0\n",
    ") -> List[Tuple[int, np.ndarray, str]]:\n",
    "    results: List[Tuple[int, np.ndarray, str]] = []\n",
    "    \n",
    "    for i, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Batch {offset}\", leave=False):\n",
    "        result: Optional[Tuple[int, np.ndarray, str]] = process_sample(row, i, mode, preprocessor, extractor, force_update)\n",
    "        if result: results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25f1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_parallel(df, mode=\"traditional\", version: Optional[int] = None, force_update_preprocessing=False, force_update_features=False, batch_size=None):\n",
    "    print(f\"ðŸ”„ Preparing features in {mode} mode...\")\n",
    "    extractor = FeatureExtractor()\n",
    "    # Get current version of features\n",
    "    if version is None: version = extractor.get_latest_version(mode)\n",
    "    X_cached, y_cached = extractor.load_cached_features(mode, version=version)\n",
    "    if X_cached is not None and not force_update_features:\n",
    "        return X_cached, y_cached\n",
    "    \n",
    "    print(\"ðŸ”„ Loading and preprocessing audio...\")\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    features_dict, labels_dict = {}, {}\n",
    "\n",
    "    # Auto-select batch size based on available memor\n",
    "    total_memory_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "    est_mem_per_sample = 0.01 if mode == \"traditional\" else 0.2\n",
    "    est_batch_size = max(10, int((total_memory_gb * 0.4) / est_mem_per_sample))\n",
    "    batch_size = batch_size or min(est_batch_size, len(df) // NUM_WORKERS)\n",
    "    if total_memory_gb < 2:\n",
    "        print(\"âš ï¸ Warning: Low memory detected. Reducing batch size to avoid OOM errors.\")\n",
    "        batch_size = min(batch_size, 10)\n",
    "    print(f\"ðŸ§  Auto-selected batch size: {batch_size} (Estimated memory per sample: {est_mem_per_sample:.2f} GB, Total RAM: {total_memory_gb:.2f} GB)\")\n",
    "\n",
    "    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    print(f\"ðŸ”„ Total batches: {len(batches)}\")\n",
    "\n",
    "    print(\"ðŸ“¦ Processing batches:\")\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_batch, batch, mode, preprocessor, extractor, force_update_preprocessing, i): i\n",
    "            for i, batch in enumerate(batches)\n",
    "            }\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"ðŸ“Š Batches Done\"):\n",
    "            batch_results = future.result()\n",
    "            if batch_results:\n",
    "                for idx, feat, label in batch_results:\n",
    "                    features_dict[idx] = feat\n",
    "                    labels_dict[idx] = label\n",
    "\n",
    "    print(\"ðŸ”„ Finished processing batches.\")\n",
    "    # for i in range(len(batches)): extractor.remove_cached_features(mode, index=i)\n",
    "\n",
    "    sorted_indices = sorted(features_dict.keys())\n",
    "    X = np.array([features_dict[i] for i in sorted_indices])\n",
    "    y = np.array([labels_dict[i] for i in sorted_indices])\n",
    "    extractor.cache_features(X, y, version=version + 1, mode=mode, force_update=force_update_features)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cd877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preparing features in traditional mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_features_parallel(df, mode=\"traditional\", force_update_features=False, force_update_preprocessing=False) # , batch_size=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dfa4d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172158, 147), (172158,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0056b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a93c72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 04:48:51,817] A new study created in memory with name: no-name-f4193e22-865c-4b27-ba84-e3dfaecff8cf\n",
      "[I 2025-05-05 04:50:42,472] Trial 1 finished with value: 0.828125 and parameters: {'learning_rate': 0.2196257654306618, 'num_leaves': 36, 'max_depth': 12}. Best is trial 1 with value: 0.828125.\n",
      "[I 2025-05-05 04:50:59,335] Trial 4 finished with value: 0.6585153345724907 and parameters: {'learning_rate': 0.010608566573098189, 'num_leaves': 38, 'max_depth': 11}. Best is trial 1 with value: 0.828125.\n",
      "[I 2025-05-05 04:51:05,096] Trial 7 finished with value: 0.7166589219330854 and parameters: {'learning_rate': 0.024830550597483316, 'num_leaves': 43, 'max_depth': 12}. Best is trial 1 with value: 0.828125.\n",
      "[I 2025-05-05 04:51:51,408] Trial 0 finished with value: 0.8427044609665427 and parameters: {'learning_rate': 0.11599343496127819, 'num_leaves': 71, 'max_depth': 12}. Best is trial 0 with value: 0.8427044609665427.\n",
      "[I 2025-05-05 04:51:52,721] Trial 8 finished with value: 0.7037058550185874 and parameters: {'learning_rate': 0.012726349414635085, 'num_leaves': 71, 'max_depth': 15}. Best is trial 0 with value: 0.8427044609665427.\n",
      "[I 2025-05-05 04:52:07,578] Trial 3 finished with value: 0.780378717472119 and parameters: {'learning_rate': 0.038434531060762084, 'num_leaves': 79, 'max_depth': 14}. Best is trial 0 with value: 0.8427044609665427.\n",
      "[I 2025-05-05 04:52:09,132] Trial 2 finished with value: 0.7442495353159851 and parameters: {'learning_rate': 0.021924616303937168, 'num_leaves': 85, 'max_depth': 14}. Best is trial 0 with value: 0.8427044609665427.\n",
      "[I 2025-05-05 04:52:14,038] Trial 9 finished with value: 0.7164846654275093 and parameters: {'learning_rate': 0.013312925944368338, 'num_leaves': 88, 'max_depth': 12}. Best is trial 0 with value: 0.8427044609665427.\n",
      "[I 2025-05-05 04:52:19,927] Trial 5 finished with value: 0.8729089219330854 and parameters: {'learning_rate': 0.14228125948257095, 'num_leaves': 119, 'max_depth': 10}. Best is trial 5 with value: 0.8729089219330854.\n",
      "[I 2025-05-05 04:52:21,481] Trial 6 finished with value: 0.875871282527881 and parameters: {'learning_rate': 0.17552815260343482, 'num_leaves': 94, 'max_depth': 14}. Best is trial 6 with value: 0.875871282527881.\n",
      "2025/05/05 04:53:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.94      0.90      0.92      5975\\n           1       0.81      0.89      0.85       989\\n           2       0.61      0.71      0.66       874\\n           3       0.78      0.82      0.80       770\\n\\n    accuracy                           0.87      8608\\n   macro avg       0.79      0.83      0.81      8608\\nweighted avg       0.88      0.87      0.88      8608\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM\n",
    "model = ModelPipeline(model=LightGBMModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10, train_size=0.85, val_size=0.1)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 03:11:53,846] A new study created in memory with name: no-name-e90c4890-9f6e-4562-a646-940736c415da\n",
      "[I 2025-05-05 03:13:38,816] Trial 1 finished with value: 0.8283573420074349 and parameters: {'learning_rate': 0.03153289111783931, 'max_depth': 8, 'n_estimators': 119, 'subsample': 0.7969329049076028, 'colsample_bytree': 0.5048800147939041, 'min_child_weight': 2}. Best is trial 1 with value: 0.8283573420074349.\n",
      "[I 2025-05-05 03:14:06,913] Trial 0 finished with value: 0.8014637546468402 and parameters: {'learning_rate': 0.0024288482682295618, 'max_depth': 8, 'n_estimators': 159, 'subsample': 0.6623757693058729, 'colsample_bytree': 0.5478323744040681, 'min_child_weight': 10}. Best is trial 1 with value: 0.8283573420074349.\n",
      "[I 2025-05-05 03:15:50,994] Trial 9 finished with value: 0.8838870817843866 and parameters: {'learning_rate': 0.07720111435762671, 'max_depth': 9, 'n_estimators': 288, 'subsample': 0.6615885828119653, 'colsample_bytree': 0.9453776353439376, 'min_child_weight': 7}. Best is trial 9 with value: 0.8838870817843866.\n",
      "[I 2025-05-05 03:16:05,414] Trial 4 finished with value: 0.8610594795539034 and parameters: {'learning_rate': 0.029588111546718452, 'max_depth': 7, 'n_estimators': 424, 'subsample': 0.5127889977777124, 'colsample_bytree': 0.8151281408580631, 'min_child_weight': 6}. Best is trial 9 with value: 0.8838870817843866.\n",
      "[I 2025-05-05 03:16:12,784] Trial 6 finished with value: 0.8188313197026023 and parameters: {'learning_rate': 0.007341993975262481, 'max_depth': 7, 'n_estimators': 445, 'subsample': 0.9402148977386593, 'colsample_bytree': 0.9471435321651311, 'min_child_weight': 6}. Best is trial 9 with value: 0.8838870817843866.\n",
      "[I 2025-05-05 03:16:55,404] Trial 3 finished with value: 0.8275441449814126 and parameters: {'learning_rate': 0.007760790975826129, 'max_depth': 10, 'n_estimators': 223, 'subsample': 0.8768491926040917, 'colsample_bytree': 0.6564008089432506, 'min_child_weight': 1}. Best is trial 9 with value: 0.8838870817843866.\n",
      "[I 2025-05-05 03:17:18,746] Trial 7 finished with value: 0.7996631040892194 and parameters: {'learning_rate': 0.0013331433475983717, 'max_depth': 7, 'n_estimators': 627, 'subsample': 0.7530739932281462, 'colsample_bytree': 0.6334553395105347, 'min_child_weight': 1}. Best is trial 9 with value: 0.8838870817843866.\n",
      "[I 2025-05-05 03:17:50,451] Trial 5 finished with value: 0.8858039033457249 and parameters: {'learning_rate': 0.04693218377476707, 'max_depth': 9, 'n_estimators': 594, 'subsample': 0.5622966727657949, 'colsample_bytree': 0.8015199434022824, 'min_child_weight': 8}. Best is trial 5 with value: 0.8858039033457249.\n",
      "[I 2025-05-05 03:17:59,790] Trial 8 finished with value: 0.8280088289962825 and parameters: {'learning_rate': 0.005045616203722197, 'max_depth': 8, 'n_estimators': 695, 'subsample': 0.5189322056579768, 'colsample_bytree': 0.6958256736523645, 'min_child_weight': 10}. Best is trial 5 with value: 0.8858039033457249.\n",
      "[I 2025-05-05 03:19:15,274] Trial 2 finished with value: 0.8757551115241635 and parameters: {'learning_rate': 0.013808600521004405, 'max_depth': 10, 'n_estimators': 820, 'subsample': 0.7206907388733053, 'colsample_bytree': 0.8146445261393652, 'min_child_weight': 3}. Best is trial 5 with value: 0.8858039033457249.\n",
      "2025/05/05 03:22:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.99      0.94     18009\\n           1       0.84      0.86      0.85      2915\\n           2       0.97      0.43      0.60      2579\\n           3       0.88      0.76      0.82      2321\\n\\n    accuracy                           0.90     25824\\n   macro avg       0.90      0.76      0.80     25824\\nweighted avg       0.90      0.90      0.89     25824\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "model = ModelPipeline(model=XGBoostModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "439bc271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 05:26:34,466] A new study created in memory with name: no-name-7fb5e60e-8fd7-4883-ab16-9297318a8746\n",
      "[I 2025-05-05 05:26:55,381] Trial 0 finished with value: 0.7687616171003717 and parameters: {'iterations': 574, 'learning_rate': 0.05824000746304977, 'depth': 12, 'l2_leaf_reg': 4.2769925577537305e-06}. Best is trial 0 with value: 0.7687616171003717.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "model = ModelPipeline(model=CatBoostModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd790bfa",
   "metadata": {},
   "source": [
    "LightGBM\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      1.00      0.97     11917\n",
    "           1       0.98      0.98      0.98      1920\n",
    "           2       0.99      0.71      0.83      1744\n",
    "           3       0.98      0.96      0.97      1635\n",
    "\n",
    "    accuracy                           0.96     17216\n",
    "   macro avg       0.97      0.91      0.94     17216\n",
    "weighted avg       0.96      0.96      0.96     17216\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.98      0.94     18009\n",
    "           1       0.85      0.85      0.85      2915\n",
    "           2       0.91      0.47      0.62      2579\n",
    "           3       0.87      0.77      0.82      2321\n",
    "\n",
    "    accuracy                           0.90     25824\n",
    "   macro avg       0.88      0.77      0.81     25824\n",
    "weighted avg       0.90      0.90      0.89     25824\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.90      0.92      5975\n",
    "           1       0.81      0.89      0.85       989\n",
    "           2       0.61      0.71      0.66       874\n",
    "           3       0.78      0.82      0.80       770\n",
    "\n",
    "    accuracy                           0.87      8608\n",
    "   macro avg       0.79      0.83      0.81      8608\n",
    "weighted avg       0.88      0.87      0.88      8608\n",
    "\n",
    "\n",
    "\n",
    "XGBoost\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.99      0.95     18009\n",
    "           1       0.86      0.87      0.86      2915\n",
    "           2       0.97      0.48      0.64      2579\n",
    "           3       0.89      0.79      0.84      2321\n",
    "\n",
    "    accuracy                           0.91     25824\n",
    "   macro avg       0.91      0.78      0.82     25824\n",
    "weighted avg       0.91      0.91      0.90     25824\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     11917\n",
    "           1       1.00      1.00      1.00      1920\n",
    "           2       1.00      1.00      1.00      1744\n",
    "           3       1.00      1.00      1.00      1635\n",
    "\n",
    "    accuracy                           1.00     17216\n",
    "   macro avg       1.00      1.00      1.00     17216\n",
    "weighted avg       1.00      1.00      1.00     17216\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.99      0.94     18009\n",
    "           1       0.84      0.86      0.85      2915\n",
    "           2       0.97      0.43      0.60      2579\n",
    "           3       0.88      0.76      0.82      2321\n",
    "\n",
    "    accuracy                           0.90     25824\n",
    "   macro avg       0.90      0.76      0.80     25824\n",
    "weighted avg       0.90      0.90      0.89     25824\n",
    "\n",
    "\n",
    "CatBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f4d05",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57ad5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No runs found in experiment 'None' with the specified criteria.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lightgbm_model \u001b[38;5;241m=\u001b[39m ModelPipeline(model\u001b[38;5;241m=\u001b[39mLightGBMModel)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlightgbm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted avg_f1-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m lightgbm_model\u001b[38;5;241m.\u001b[39mclassification_report(X, y)\n",
      "File \u001b[1;32me:\\College\\4- Senior 2\\Semester 2\\Pattern\\Project\\modules\\pipelines.py:21\u001b[0m, in \u001b[0;36mModelPipeline.load_model\u001b[1;34m(self, run_id, experiment_id, experiment_name, best_metric, maximize, additional_tags)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, experiment_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, experiment_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, best_metric: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, maximize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, additional_tags: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_tags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\College\\4- Senior 2\\Semester 2\\Pattern\\Project\\models\\base_model.py:109\u001b[0m, in \u001b[0;36mBaseModel.load_model_from_run\u001b[1;34m(self, run_id, experiment_id, experiment_name, best_metric, maximize, additional_tags)\u001b[0m\n\u001b[0;32m    100\u001b[0m runs \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msearch_runs(\n\u001b[0;32m    101\u001b[0m     experiment_ids\u001b[38;5;241m=\u001b[39m[experiment_id] \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    102\u001b[0m     experiment_names\u001b[38;5;241m=\u001b[39m[experiment_name] \u001b[38;5;28;01mif\u001b[39;00m experiment_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    106\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runs\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo runs found in experiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with the specified criteria.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Get the best or last run\u001b[39;00m\n\u001b[0;32m    112\u001b[0m run \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mget_run(runs\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: No runs found in experiment 'None' with the specified criteria."
     ]
    }
   ],
   "source": [
    "lightgbm_model = ModelPipeline(model=LightGBMModel)\n",
    "lightgbm_model.load_model(best_metric=\"weighted avg_f1-score\")\n",
    "lightgbm_model.classification_report(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb979e43",
   "metadata": {},
   "source": [
    "# Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Batch Inference Utility ===\n",
    "def run_batch_inference(model, input_folder, output_path, sr=16000, feature_mode=\"traditional\"):\n",
    "    extractor = FeatureExtractor()\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    results = []\n",
    "\n",
    "    for file in Path(input_folder).rglob(\"*.wav\"):\n",
    "        y = preprocessor.preprocess(preprocessor.load_audio(str(file), sr=sr))\n",
    "        if y is not None:\n",
    "            x = extractor.extract(y, sr=sr, mode=feature_mode).reshape(1, -1)\n",
    "            pred = model.predict(x)[0]\n",
    "            results.append({\"file\": file.name, \"prediction\": pred})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Batch inference saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
