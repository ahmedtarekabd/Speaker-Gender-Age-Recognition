{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c70e91e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7065cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.preprocessing import AudioPreprocessor\n",
    "from modules.feature_extraction import FeatureExtractor\n",
    "from modules.pipelines import ModelPipeline\n",
    "from modules.evaluate import PerformanceAnalyzer\n",
    "\n",
    "from models.catboost import CatBoostModel\n",
    "from models.lightgbm import LightGBMModel\n",
    "from models.xgboost import XGBoostModel\n",
    "from models.gmboost import GradientBoostingModel\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b2f43",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87cda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import run_config, NUM_WORKERS, DATA_DIR, AUDIO_PATH\n",
    "\n",
    "run_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392b58d",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ec207a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                           path                          sentence  up_votes  \\\n",
       "0  common_voice_en_19687170.mp3  He associated with the Formists.         2   \n",
       "\n",
       "   down_votes      age  gender accent  label  \n",
       "0           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_DIR / \"filtered_data_labeled.tsv\", sep='\\t')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7518fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...</td>\n",
       "      <td>data\\audios\\common_voice_en_19687170.mp3</td>\n",
       "      <td>He associated with the Formists.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>fifties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  5001d9a0d3f8f5aae6f386f70713b2d5d046edc7ba0068...   \n",
       "\n",
       "                                       path                          sentence  \\\n",
       "0  data\\audios\\common_voice_en_19687170.mp3  He associated with the Formists.   \n",
       "\n",
       "   up_votes  down_votes      age  gender accent  label  \n",
       "0         2           1  fifties  female     us      3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path'] = df['path'].apply(lambda x: AUDIO_PATH / x)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a52cb",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List\n",
    "\n",
    "# === Parallel Processing ===\n",
    "def process_sample(\n",
    "    row: pd.Series, \n",
    "    idx: int, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool\n",
    ") -> Optional[Tuple[int, np.ndarray, str]]:\n",
    "\n",
    "    y_proc: Optional[np.ndarray] = preprocessor.load_cached_preprocessed(idx) if not force_update else None\n",
    "    \n",
    "    # Load and preprocess audio if not cached or force_update is True\n",
    "    if y_proc is None or force_update:\n",
    "        y_raw: Optional[np.ndarray] = preprocessor.load_audio(row['path'])\n",
    "        if y_raw is None:\n",
    "            # print(f\"Failed to load audio for index {idx}.\")\n",
    "            return None\n",
    "        y_proc = preprocessor.preprocess(y_raw)\n",
    "        preprocessor.cache_preprocessed(idx, y_proc, force_update)\n",
    "    \n",
    "    # Extract features\n",
    "    feat = extractor.extract(y_proc, sr=16000, mode=mode)\n",
    "    return idx, feat, row['label']\n",
    "\n",
    "\n",
    "def process_batch(\n",
    "    batch_df: pd.DataFrame, \n",
    "    mode: str, \n",
    "    preprocessor: AudioPreprocessor, \n",
    "    extractor: FeatureExtractor, \n",
    "    force_update: bool, \n",
    "    offset: int = 0\n",
    ") -> List[Tuple[int, np.ndarray, str]]:\n",
    "    results: List[Tuple[int, np.ndarray, str]] = []\n",
    "    \n",
    "    for i, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f\"Batch {offset}\", leave=False):\n",
    "        result: Optional[Tuple[int, np.ndarray, str]] = process_sample(row, i, mode, preprocessor, extractor, force_update)\n",
    "        if result: results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25f1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_parallel(df, mode=\"traditional\", force_update_preprocessing=False, force_update_features=False, batch_size=None):\n",
    "    print(f\"ðŸ”„ Preparing features in {mode} mode...\")\n",
    "    extractor = FeatureExtractor()\n",
    "    X_cached, y_cached = extractor.load_cached_features(mode)\n",
    "    if X_cached is not None and not force_update_features:\n",
    "        return X_cached, y_cached\n",
    "    \n",
    "    print(\"ðŸ”„ Loading and preprocessing audio...\")\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    features_dict, labels_dict = {}, {}\n",
    "\n",
    "    # Auto-select batch size based on available memor\n",
    "    total_memory_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "    est_mem_per_sample = 0.01 if mode == \"traditional\" else 0.2\n",
    "    est_batch_size = max(10, int((total_memory_gb * 0.4) / est_mem_per_sample))\n",
    "    batch_size = batch_size or min(est_batch_size, len(df) // NUM_WORKERS)\n",
    "    if total_memory_gb < 2:\n",
    "        print(\"âš ï¸ Warning: Low memory detected. Reducing batch size to avoid OOM errors.\")\n",
    "        batch_size = min(batch_size, 10)\n",
    "    print(f\"ðŸ§  Auto-selected batch size: {batch_size} (Estimated memory per sample: {est_mem_per_sample:.2f} GB, Total RAM: {total_memory_gb:.2f} GB)\")\n",
    "\n",
    "    batches = [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "    print(f\"ðŸ”„ Total batches: {len(batches)}\")\n",
    "\n",
    "    print(\"ðŸ“¦ Processing batches:\")\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(process_batch, batch, mode, preprocessor, extractor, force_update_preprocessing, i): i\n",
    "            for i, batch in enumerate(batches)\n",
    "            }\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"ðŸ“Š Batches Done\"):\n",
    "            batch_results = future.result()\n",
    "            if batch_results:\n",
    "                for idx, feat, label in batch_results:\n",
    "                    features_dict[idx] = feat\n",
    "                    labels_dict[idx] = label\n",
    "\n",
    "    print(\"ðŸ”„ Finished processing batches.\")\n",
    "    # for i in range(len(batches)): extractor.remove_cached_features(mode, index=i)\n",
    "\n",
    "    sorted_indices = sorted(features_dict.keys())\n",
    "    X = np.array([features_dict[i] for i in sorted_indices])\n",
    "    y = np.array([labels_dict[i] for i in sorted_indices])\n",
    "    extractor.cache_features(X, y, mode=mode, force_update=force_update_features)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cd877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preparing features in traditional mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_features_parallel(df, mode=\"traditional\", force_update_features=False, force_update_preprocessing=False) # , batch_size=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dfa4d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((172158, 147), (172158,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0056b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a93c72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 13:06:26,450] A new study created in memory with name: no-name-a3e01ce7-1125-444a-894b-a497387e6cac\n",
      "[I 2025-04-26 13:07:05,744] Trial 9 finished with value: 0.7918796468401487 and parameters: {'learning_rate': 0.02351149351726154, 'num_leaves': 102, 'max_depth': 4}. Best is trial 9 with value: 0.7918796468401487.\n",
      "[I 2025-04-26 13:07:29,884] Trial 0 finished with value: 0.6922049256505576 and parameters: {'learning_rate': 0.0015588977578208834, 'num_leaves': 23, 'max_depth': 8}. Best is trial 9 with value: 0.7918796468401487.\n",
      "[I 2025-04-26 13:07:30,521] Trial 7 finished with value: 0.774860594795539 and parameters: {'learning_rate': 0.010801054674113093, 'num_leaves': 48, 'max_depth': 5}. Best is trial 9 with value: 0.7918796468401487.\n",
      "[I 2025-04-26 13:07:44,459] Trial 1 finished with value: 0.8702369888475836 and parameters: {'learning_rate': 0.18408099003672337, 'num_leaves': 36, 'max_depth': 8}. Best is trial 1 with value: 0.8702369888475836.\n",
      "[I 2025-04-26 13:08:26,083] Trial 3 finished with value: 0.6922049256505576 and parameters: {'learning_rate': 0.001763190996428901, 'num_leaves': 70, 'max_depth': 10}. Best is trial 1 with value: 0.8702369888475836.\n",
      "[I 2025-04-26 13:08:26,359] Trial 2 finished with value: 0.8780204460966543 and parameters: {'learning_rate': 0.16150572232331495, 'num_leaves': 62, 'max_depth': 11}. Best is trial 2 with value: 0.8780204460966543.\n",
      "[I 2025-04-26 13:08:34,313] Trial 4 finished with value: 0.8276603159851301 and parameters: {'learning_rate': 0.02459932054376723, 'num_leaves': 90, 'max_depth': 8}. Best is trial 2 with value: 0.8780204460966543.\n",
      "[I 2025-04-26 13:08:48,945] Trial 6 finished with value: 0.8222583643122676 and parameters: {'learning_rate': 0.01627102330025901, 'num_leaves': 115, 'max_depth': 10}. Best is trial 2 with value: 0.8780204460966543.\n",
      "[I 2025-04-26 13:08:50,660] Trial 8 finished with value: 0.8904507434944238 and parameters: {'learning_rate': 0.27028579018621557, 'num_leaves': 129, 'max_depth': 10}. Best is trial 8 with value: 0.8904507434944238.\n",
      "[I 2025-04-26 13:08:51,728] Trial 5 finished with value: 0.845724907063197 and parameters: {'learning_rate': 0.03800009301216075, 'num_leaves': 149, 'max_depth': 8}. Best is trial 8 with value: 0.8904507434944238.\n",
      "2025/04/26 13:09:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00     11917\\n           1       1.00      1.00      1.00      1920\\n           2       1.00      0.99      0.99      1744\\n           3       1.00      1.00      1.00      1635\\n\\n    accuracy                           1.00     17216\\n   macro avg       1.00      1.00      1.00     17216\\nweighted avg       1.00      1.00      1.00     17216\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM\n",
    "model = ModelPipeline(model=LightGBMModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698e2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 13:09:36,602] A new study created in memory with name: no-name-59532b30-dfeb-4fb8-8b2a-05200871f29c\n",
      "[I 2025-04-26 13:14:05,651] Trial 4 finished with value: 0.7794493494423792 and parameters: {'learning_rate': 0.0016911611836628866, 'max_depth': 5, 'n_estimators': 150, 'subsample': 0.912039132908897, 'colsample_bytree': 0.7886613496002368}. Best is trial 4 with value: 0.7794493494423792.\n",
      "[I 2025-04-26 13:14:06,066] Trial 2 finished with value: 0.8363150557620818 and parameters: {'learning_rate': 0.057761785377502387, 'max_depth': 7, 'n_estimators': 106, 'subsample': 0.6532688090324347, 'colsample_bytree': 0.8209852684032211}. Best is trial 2 with value: 0.8363150557620818.\n",
      "[I 2025-04-26 13:25:57,601] Trial 9 finished with value: 0.7950743494423792 and parameters: {'learning_rate': 0.006273522111194924, 'max_depth': 4, 'n_estimators': 763, 'subsample': 0.7495534446454752, 'colsample_bytree': 0.6465407785925488}. Best is trial 2 with value: 0.8363150557620818.\n",
      "[I 2025-04-26 13:26:03,634] Trial 5 finished with value: 0.8357342007434945 and parameters: {'learning_rate': 0.0382363108110744, 'max_depth': 3, 'n_estimators': 961, 'subsample': 0.60426777883748, 'colsample_bytree': 0.8439314080009809}. Best is trial 2 with value: 0.8363150557620818.\n",
      "[I 2025-04-26 13:30:24,864] Trial 0 finished with value: 0.816682156133829 and parameters: {'learning_rate': 0.006148021682296481, 'max_depth': 6, 'n_estimators': 714, 'subsample': 0.6425554492832426, 'colsample_bytree': 0.6774796447269658}. Best is trial 2 with value: 0.8363150557620818.\n",
      "[I 2025-04-26 13:33:26,651] Trial 7 finished with value: 0.8770329925650557 and parameters: {'learning_rate': 0.03281851371722499, 'max_depth': 10, 'n_estimators': 478, 'subsample': 0.8785009984367538, 'colsample_bytree': 0.9921810149569481}. Best is trial 7 with value: 0.8770329925650557.\n",
      "[I 2025-04-26 13:34:13,187] Trial 8 finished with value: 0.7985594795539034 and parameters: {'learning_rate': 0.002195346582172022, 'max_depth': 6, 'n_estimators': 887, 'subsample': 0.9428120935704603, 'colsample_bytree': 0.7337594761272362}. Best is trial 7 with value: 0.8770329925650557.\n",
      "[I 2025-04-26 13:35:41,448] Trial 6 finished with value: 0.8845841078066915 and parameters: {'learning_rate': 0.03472732249072176, 'max_depth': 7, 'n_estimators': 918, 'subsample': 0.7021758855762741, 'colsample_bytree': 0.9567353236509046}. Best is trial 6 with value: 0.8845841078066915.\n",
      "[I 2025-04-26 13:37:34,128] Trial 3 finished with value: 0.8632086431226765 and parameters: {'learning_rate': 0.010677750502635098, 'max_depth': 10, 'n_estimators': 651, 'subsample': 0.6776120817442842, 'colsample_bytree': 0.8482337785070995}. Best is trial 6 with value: 0.8845841078066915.\n",
      "[I 2025-04-26 13:39:40,353] Trial 1 finished with value: 0.8494423791821561 and parameters: {'learning_rate': 0.005515219758566679, 'max_depth': 10, 'n_estimators': 871, 'subsample': 0.8577899864487839, 'colsample_bytree': 0.5172986415676627}. Best is trial 6 with value: 0.8845841078066915.\n",
      "2025/04/26 13:43:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.97      1.00      0.98     11917\\n           1       0.99      0.99      0.99      1920\\n           2       1.00      0.80      0.89      1744\\n           3       0.99      0.98      0.99      1635\\n\\n    accuracy                           0.98     17216\\n   macro avg       0.99      0.94      0.96     17216\\nweighted avg       0.98      0.98      0.97     17216\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "model = ModelPipeline(model=XGBoostModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439bc271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-30 16:03:33,723] A new study created in memory with name: no-name-7be00644-8876-4fa2-864f-6b48f99e1d33\n",
      "[I 2025-04-30 16:03:57,990] Trial 0 finished with value: 0.8123257434944238 and parameters: {'iterations': 617, 'learning_rate': 0.007630827081460776, 'depth': 8, 'l2_leaf_reg': 0.009735441086428834}. Best is trial 0 with value: 0.8123257434944238.\n",
      "[I 2025-04-30 16:04:08,591] Trial 1 finished with value: 0.7638824349442379 and parameters: {'iterations': 933, 'learning_rate': 0.037320437338869826, 'depth': 10, 'l2_leaf_reg': 1.241515815615068e-06}. Best is trial 0 with value: 0.8123257434944238.\n",
      "[I 2025-04-30 16:04:15,004] Trial 2 finished with value: 0.7466310408921933 and parameters: {'iterations': 604, 'learning_rate': 0.003970742882116975, 'depth': 5, 'l2_leaf_reg': 1.4860765108197247e-07}. Best is trial 0 with value: 0.8123257434944238.\n",
      "[I 2025-04-30 16:04:33,596] Trial 3 finished with value: 0.8805762081784386 and parameters: {'iterations': 934, 'learning_rate': 0.08875839726942937, 'depth': 6, 'l2_leaf_reg': 0.026050953480818227}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:04:40,864] Trial 4 finished with value: 0.7589451672862454 and parameters: {'iterations': 117, 'learning_rate': 0.007987186540052177, 'depth': 4, 'l2_leaf_reg': 6.426205216024589}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:04:47,820] Trial 5 finished with value: 0.7496514869888475 and parameters: {'iterations': 646, 'learning_rate': 0.026362185219378206, 'depth': 6, 'l2_leaf_reg': 4.6483535754080404e-05}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:04:54,341] Trial 6 finished with value: 0.7390799256505576 and parameters: {'iterations': 948, 'learning_rate': 0.002704263711774853, 'depth': 4, 'l2_leaf_reg': 5.634209973213626e-07}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:05:08,442] Trial 7 finished with value: 0.7700975836431226 and parameters: {'iterations': 744, 'learning_rate': 0.0025913987809515473, 'depth': 5, 'l2_leaf_reg': 7.534144149477289}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:05:15,667] Trial 8 finished with value: 0.7496514869888475 and parameters: {'iterations': 544, 'learning_rate': 0.005506970370598562, 'depth': 6, 'l2_leaf_reg': 7.016391001378576e-06}. Best is trial 3 with value: 0.8805762081784386.\n",
      "[I 2025-04-30 16:05:29,458] Trial 9 finished with value: 0.8128485130111525 and parameters: {'iterations': 334, 'learning_rate': 0.02503556208442349, 'depth': 7, 'l2_leaf_reg': 44.940635877449814}. Best is trial 3 with value: 0.8805762081784386.\n",
      "2025/04/30 16:07:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.91      0.99      0.95     11917\\n           1       0.90      0.91      0.90      1920\\n           2       0.96      0.46      0.62      1744\\n           3       0.91      0.83      0.87      1635\\n\\n    accuracy                           0.91     17216\\n   macro avg       0.92      0.80      0.83     17216\\nweighted avg       0.91      0.91      0.90     17216\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost\n",
    "model = ModelPipeline(model=CatBoostModel)\n",
    "metrics = model.train(X, y, use_optuna=True, n_trials=10)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67c5f0",
   "metadata": {},
   "source": [
    "LightGBM\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     11917\n",
    "           1       1.00      1.00      1.00      1920\n",
    "           2       1.00      0.99      0.99      1744\n",
    "           3       1.00      1.00      1.00      1635\n",
    "\n",
    "    accuracy                           1.00     17216\n",
    "   macro avg       1.00      1.00      1.00     17216\n",
    "weighted avg       1.00      1.00      1.00     17216\n",
    "\n",
    "XGBoost\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      1.00      0.98     11917\n",
    "           1       0.99      0.99      0.99      1920\n",
    "           2       1.00      0.80      0.89      1744\n",
    "           3       0.99      0.98      0.99      1635\n",
    "\n",
    "    accuracy                           0.98     17216\n",
    "   macro avg       0.99      0.94      0.96     17216\n",
    "weighted avg       0.98      0.98      0.97     17216\n",
    "\n",
    "CatBoost\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.99      0.95     11917\n",
    "           1       0.90      0.91      0.90      1920\n",
    "           2       0.96      0.46      0.62      1744\n",
    "           3       0.91      0.83      0.87      1635\n",
    "\n",
    "    accuracy                           0.91     17216\n",
    "   macro avg       0.92      0.80      0.83     17216\n",
    "weighted avg       0.91      0.91      0.90     17216"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb979e43",
   "metadata": {},
   "source": [
    "# Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008efd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Batch Inference Utility ===\n",
    "def run_batch_inference(model, input_folder, output_path, sr=16000, feature_mode=\"traditional\"):\n",
    "    extractor = FeatureExtractor()\n",
    "    preprocessor = AudioPreprocessor()\n",
    "    results = []\n",
    "\n",
    "    for file in Path(input_folder).rglob(\"*.wav\"):\n",
    "        y = preprocessor.preprocess(preprocessor.load_audio(str(file), sr=sr))\n",
    "        if y is not None:\n",
    "            x = extractor.extract(y, sr=sr, mode=feature_mode).reshape(1, -1)\n",
    "            pred = model.predict(x)[0]\n",
    "            results.append({\"file\": file.name, \"prediction\": pred})\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… Batch inference saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
