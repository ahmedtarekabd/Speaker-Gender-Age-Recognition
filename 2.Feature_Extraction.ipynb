{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ef3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "from IPython import get_ipython\n",
    "with io.capture_output() as captured:  \n",
    "   get_ipython().run_line_magic('run', '1.Preprocessing.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc2fb3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfaad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c9d7c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d2b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import run_config\n",
    "\n",
    "run_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d03f354",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b885a",
   "metadata": {},
   "source": [
    "## Enhanced Feature Extraction Pipeline (Traditional + Prosodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19764ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(y, sr=16000, n_mfcc=20, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Extracts various audio features from the given audio signal.\n",
    "    Args:\n",
    "        y (numpy.ndarray): Audio time series.\n",
    "        sr (int): Sampling rate of `y`.\n",
    "        n_mfcc (int): Number of MFCCs to return.\n",
    "        n_fft (int): Length of the FFT window.\n",
    "        hop_length (int): Number of samples between frames.\n",
    "        Returns:\n",
    "        numpy.ndarray: Extracted features.\n",
    "    \"\"\"\n",
    "    # MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    \n",
    "    # Chroma\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "    # Spectral Contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "\n",
    "    # Tonnetz\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "\n",
    "    # Energy & ZCR\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "    # Concatenate all\n",
    "    features = np.concatenate([\n",
    "        mfcc.mean(axis=1),\n",
    "        delta.mean(axis=1),\n",
    "        delta2.mean(axis=1),\n",
    "        chroma.mean(axis=1),\n",
    "        contrast.mean(axis=1),\n",
    "        tonnetz.mean(axis=1),\n",
    "        [rmse.mean()],\n",
    "        [zcr.mean()]\n",
    "    ])\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70559012",
   "metadata": {},
   "source": [
    "## `wav2vec` for Age & Gender Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b73031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio\n",
    "# import torch\n",
    "# from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "\n",
    "# # Load pretrained model (wav2vec base or large)\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# def extract_wav2vec_features(y, sr=16000):\n",
    "#     # Resample to 16kHz if necessary\n",
    "#     if sr != 16000:\n",
    "#         y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "    \n",
    "#     input_values = processor(y, return_tensors=\"pt\", sampling_rate=16000).input_values\n",
    "#     with torch.no_grad():\n",
    "#         embeddings = model(input_values).last_hidden_state\n",
    "\n",
    "#     # Mean pooling across time dimension\n",
    "#     features = embeddings.mean(dim=1).squeeze().numpy()\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4861b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147,),\n",
       " array([-350.35125732,   20.87301636,   43.61044312,   10.20368767,\n",
       "          -8.32745934,   -1.96336699,  -30.76938057,   -8.0605526 ,\n",
       "         -10.44402122,   -2.19611549]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = extract_features(df['audio_data'][0], n_mfcc=40)\n",
    "tmp.shape, tmp[:10]  # Check the shape and first 10 values of the feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8dbf2e",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:03<00:00, 144.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df['features'] = df['audio_data'].progress_apply(lambda y: extract_features(y=y, sr=16000, n_mfcc=40))\n",
    "\n",
    "X = np.stack(df['features'].values)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b07f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
