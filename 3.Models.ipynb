{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bc2fb3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfaad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c9d7c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import run_config\n",
    "\n",
    "run_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c68c3c",
   "metadata": {},
   "source": [
    "# High Accuracy Pipeline (XGBoost/CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30165a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 300, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10, log=True),\n",
    "        \"task_type\": \"GPU\" if CatBoostClassifier().get_param(\"task_type\") == \"GPU\" else \"CPU\",\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=False)\n",
    "    return 1 - model.score(X_val, y_val)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective_catboost, n_trials=20)\n",
    "\n",
    "best_model_catboost = CatBoostClassifier(**study.best_params)\n",
    "best_model_catboost.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc3280",
   "metadata": {},
   "source": [
    "# High Speed Pipeline (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": len(set(y_train)),\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
    "    return 1 - model.score(X_val, y_val)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective_lightgbm, n_trials=20)\n",
    "\n",
    "best_model_lgb = lgb.LGBMClassifier(**study.best_params)\n",
    "best_model_lgb.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
